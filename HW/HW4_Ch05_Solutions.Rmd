---
title: "HW 4 Solutions"
author: "Shravan Vasishth"
date: ""
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

source("index.R")
```

# Exercise 1

```{r}
data("df_pupil_complete")
df_pupil_complete <- df_pupil_complete %>%
  mutate(c_load = load - mean(load))
```

Fit a "maximal" model (correlated varying intercept and slopes for subjects) assuming a normal likelihood.

```{r fitpupil, message = FALSE, results = "hide",cache=TRUE}
fit_pupil <- brm(p_size ~ 1 + c_load + (c_load | subj),
  data = df_pupil_complete,
  family = gaussian(),
  prior = c(
    prior(normal(1000, 500), class = Intercept),
    prior(normal(0, 1000), class = sigma),
    prior(normal(0, 100), class = b, coef = c_load),
    prior(normal(0, 1000), class = sd),
    prior(lkj(2), class = cor)),
  control=list(adapt_delta=0.99, max_treedepth=15))
```

### (a)  Examine the effect of load on pupil size, and the average pupil size.

```{r}
fit_pupil
```

If we want to just report the change in pupil size as a function of one unit increase in (centered) load:

```{r}
posterior_summary(fit_pupil, variable = "b_c_load")
```

There isn't a clear effect of load across all the subject.

But the intercept seems to be quite large,

```{r}
posterior_summary(fit_pupil, variable = "b_Intercept")
```

and we assumed that it shouldn't be:

```{r}
brms::prior_summary(fit_pupil)
```

See the row with class Intercept.

So maybe our prior for the intercept was overly informative.


## (b) Do a sensitivity analysis for the prior on the intercept ($\alpha$). What is the estimate of the effect ($\beta$) under different priors?

We'll try a wider prior for $\alpha$. A more complete sensitivity analysis would investigate several possible priors

$$\alpha \sim \mathit{Normal(4000,2000)}$$

```{r fitpupil2, message = FALSE, results = "hide",cache=TRUE}
fit_pupil_2 <- brm(p_size ~ 1 + c_load + (c_load | subj),
  data = df_pupil_complete,
  family = gaussian(),
  prior = c(
    prior(normal(4000, 2000), class = Intercept),
    prior(normal(0, 1000), class = sigma),
    prior(normal(0, 100), class = b, coef = c_load),
    prior(normal(0, 2000), class = sd),
  prior(lkj(2), class = cor))
)
```

```{r}
fit_pupil_2
```

Now there seems to be a clear effect! Our bad prior for the intercept was messing up our inferences!

## (c) Is the effect of load consistent across subjects?

```{r}
## For the hierarchical model, this is more complicated,
# because we want the effect (beta) + adjustment:
# we extract the overall group level effect:
beta <- c(as_draws_df(fit_pupil_2)$b_c_load)
# We extract the individual adjustments
ind_effects_v <- paste0("r_subj[", unique(df_pupil_complete$subj), ",c_load]")
adjustment <- as.matrix(as_draws_df(fit_pupil)[ind_effects_v])
# We get the by subject effects in a data frame where each adjustment
# is in each column.
by_subj_effect <- as_tibble(beta + adjustment)
# We summarize them by getting a table with the mean and the
# quantiles for each column and then binding them.
par_h <- lapply(by_subj_effect, function(x) {
  tibble(
    Estimate = mean(x),
    Q2.5 = quantile(x, .025),
    Q97.5 = quantile(x, .975)
  )
}) %>%
  bind_rows() %>%
  # We add a column to identify that the model,
  # and one with the subject labels:
  mutate(
    subj = unique(df_pupil_complete$subj))%>%
  arrange(Estimate) %>%
  mutate(subj = factor(subj, levels = subj))


ggplot(
  par_h,
  aes(
    ymin = Q2.5, ymax = Q97.5, x = subj, y = Estimate
  )
) +
  geom_errorbar() +
  geom_point() +
  # We'll also add the mean and 95% CrI of the overall difference
  # to the plot:
  geom_hline(
    yintercept =
      posterior_summary(fit_pupil_2)["b_c_load", "Estimate"]
  ) +
  geom_hline(
    yintercept =
      posterior_summary(fit_pupil_2)["b_c_load", "Q2.5"],
    linetype = "dotted", linewidth = 0.5
  ) +
  geom_hline(
    yintercept =
      posterior_summary(fit_pupil_2)["b_c_load", "Q97.5"],
    linetype = "dotted", linewidth = 0.5
  ) +
  xlab("Change in pupil size") +
  coord_flip()
```



# Exercise 2

We are going to fit the data with the following log-normal likelihood:

 \begin{equation}
  rt_n \sim LogNormal(\alpha + u_{i[n],0} + w_{j[n],0} + c\_cond_n \cdot  (\beta + u_{i[n],1}+ w_{j[n],1}), \sigma)
  \end{equation}

We can use similar priors as we used for the Stroop task paying attention to use a not too tight prior for $\beta$:


* Priors:
 \begin{equation}
 \begin{aligned}
   \alpha & \sim Normal(6, 1.5) \\
   \beta  & \sim Normal(0, 0.1) \\
    \sigma  &\sim Normal_+(0, 1)
 \end{aligned}
 \end{equation}

Here, we will need priors for the group-level parameters. Given that we assume a correlation between by-subject intercept and slope, and by-item intercept and slope, our model has the following structure which requires us to assign priors to $\Sigma_u$ and $\Sigma_w$

 \begin{equation}
 \begin{aligned}
    {\begin{pmatrix}
    u_{i,0} \\
    u_{i,1}
    \end{pmatrix}}
   &\sim {\mathcal {N}}
    \left(
   {\begin{pmatrix}
    0\\
    0
   \end{pmatrix}}
 ,\boldsymbol{\Sigma_u} \right) \\
     {\begin{pmatrix}
    w_{i,0} \\
    w_{i,1}
    \end{pmatrix}}
   &\sim {\mathcal {N}}
    \left(
   {\begin{pmatrix}
    0\\
    0
   \end{pmatrix}}
 ,\boldsymbol{\Sigma_w} \right)
 \end{aligned}
 \end{equation}

\begin{equation}
\begin{aligned}
 \boldsymbol{\Sigma_u} & =
{\begin{pmatrix}
\tau_{u_0}^2 & \rho_u \tau_{u_0} \tau_{u_1} \\
\rho_u \tau_{u_0} \tau_{u_1} & \tau_{u_1}^2
\end{pmatrix}}\\
 \boldsymbol{\Sigma_w} & =
{\begin{pmatrix}
\tau_{w_0}^2 & \rho_w \tau_{w_0} \tau_{w_1} \\
\rho_w \tau_{w_0} \tau_{w_1} & \tau_{w_1}^2
\end{pmatrix}}
 \end{aligned}
\end{equation}

In practice this means that we need priors for the by-subject and by-item variances and correlations:
\begin{equation}
\begin{aligned}
\tau_{u_0} &\sim Normal_+(0,1)\\
\tau_{u_1} &\sim Normal_+(0,1)\\
\rho_u &\sim LKJcorr(2) \\
\tau_{w_0} &\sim Normal_+(0,1)\\
\tau_{w_1} &\sim Normal_+(0,1)\\
\rho_w &\sim LKJcorr(2) \\
\end{aligned}
\end{equation}

Read the data:

```{r open_grodneretal, message = FALSE}
data("df_gg05_rc")
df_gg05_rc <- df_gg05_rc %>%
  mutate(c_cond = if_else(condition == "objgap", 1/2, -1/2))
```

We're ready to fit a model now:

```{r, message = FALSE, results = "hide", cache=TRUE}
fit_df_gg05_rc <- brm(RT ~ c_cond + (c_cond | subj) + (c_cond | item),
  family = lognormal(),
  iter = 10000,
  prior =
    c(
      prior(normal(6, 1.5), class = Intercept),
      prior(normal(0, .1), class = b),
      prior(normal(0, 1), class = sigma),
      prior(normal(0, 1), class = sd),
      prior(lkj(2), class = cor)
    ),
  data = df_gg05_rc,
  control=list(adapt_delta=0.99, max_treedepth=15)
)
```

## (a) Examine the effect of relative clause attachment site (the predictor `c_cond`) on reading times `RT` in log-scale.

We'll focus on $\beta$:

```{r}
posterior_summary(fit_df_gg05_rc, variable = "b_c_cond")
```

## (b) Estimate the median difference between relative clause attachment sites in milliseconds, and report the mean and 95% CI.

```{r}
alpha <- as_draws_df(fit_df_gg05_rc)$b_Intercept
beta <- as_draws_df(fit_df_gg05_rc)$b_c_cond
# Difference between object RC coded as .5 and subject RC coded as .5
effect <- exp(alpha + beta * .5) - exp(alpha + beta * -.5)
c(mean = mean(effect), quantile(effect, c(.025,.975)))
```
## (c) Do a sensitivity analysis. What is the estimate of the effect ($\beta$) under different priors? What is the difference in milliseconds between conditions under different priors?

Next, we do a sensitivity analysis using a tighter prior for $\beta$, $\beta \sim Normal(0, 0.01)$:

```{r, message = FALSE, results = "hide", cache=TRUE}
fit_df_gg05_rc2 <- brm(RT ~ c_cond + (c_cond | subj) + (c_cond | item),
  family = lognormal(),
  prior =
    c(
      prior(normal(6, 1.5), class = Intercept),
      prior(normal(0, 0.01), class = b),
      prior(normal(0, 1), class = sigma),
      prior(normal(0, 1), class = sd),
      prior(lkj(2), class = cor)
    ),
  data = df_gg05_rc,
  control=list(adapt_delta=0.99, max_treedepth=15)
)
```

```{r, fig.height = 11}
posterior_summary(fit_df_gg05_rc2, variable = "b_c_cond")
```

And here we use the prior, $\beta \sim Normal(0, 1)$:

```{r, message = FALSE, results = "hide", cache=TRUE}
fit_df_gg05_rc3 <- brm(RT ~ c_cond + (c_cond | subj) + (c_cond | item),
  family = lognormal(),
  prior =
    c(
      prior(normal(6, 1.5), class = Intercept),
      prior(normal(0, 1), class = b),
      prior(normal(0, 1), class = sigma),
      prior(normal(0, 1), class = sd),
      prior(lkj(2), class = cor)
    ),
  data = df_gg05_rc,
  control=list(adapt_delta=0.99, max_treedepth=15)
)
```

```{r, fig.height = 11}
posterior_summary(fit_df_gg05_rc3, variable = "b_c_cond")
```
We can summarize the estimates of $\beta$ given different priors in the following way:

```{r, echo = FALSE, results = "asis"}
select <- dplyr::select

list(fit_df_gg05_rc, fit_df_gg05_rc2, fit_df_gg05_rc3) %>%
  map_dfr(~
  posterior_summary(.x, variable = "b_c_cond") %>%
    as_tibble() %>%
    select(-Est.Error)) %>%
  mutate("Prior for $\\beta$" = c("Normal(0,.01)", "Normal(0,.1)", "Normal(0,1)")) %>%
  knitr::kable(escape = FALSE)
```

We can take a look at the estimate for the difference between conditions in milliseconds:

```{r}
alpha <- as_draws_df(fit_df_gg05_rc)$b_Intercept
beta1 <- as_draws_df(fit_df_gg05_rc)$b_c_cond
diff1 <- exp(alpha + beta1/2) - exp(alpha - beta1/2)
c(mean = mean(diff1), quantile(diff1, c(.025, .975)))
```

If we repeat this with each model, we can take a look at the effect of the prior on the difference between conditions:

```{r, echo = FALSE, results ="asis"}
list(fit_df_gg05_rc, fit_df_gg05_rc2, fit_df_gg05_rc3) %>%
  map_dfr(~ {
    alpha <- as_draws_df(.x)$b_Intercept
    beta <- as_draws_df(.x)$b_c_cond
    diff <- exp(alpha + beta/2) - exp(alpha - beta/2)
    c(mean = mean(diff), quantile(diff, c(.025, .975))) %>%
      bind_rows() %>%
      setNames(c("Estimate (ms)", "Q2.5", "Q97.5"))
  }) %>%
  mutate("Prior for $\\beta$" = c("Normal(0,.01)", "Normal(0,.1)", "Normal(0,1)")) %>%
  knitr::kable(escape = FALSE)
```

This sensitivity shows us that the posterior changes quite a lot under different priors; depending on what we consider to be a reasonable prior (i.e., depending on our prior beliefs), the inference that we derive from the model and data can vary quite a bit when the data are relatively sparse, as in this case.

# Exercise 3

```{r}
data("df_gibsonwu")
df_gibsonwu$cond<-ifelse(df_gibsonwu$type=="obj-ext",0.5,-0.5)

data("df_gibsonwu2")
df_gibsonwu2$cond<-ifelse(df_gibsonwu2$condition=="obj-ext",0.5,-0.5)
```

## Analysis of Gibson and Wu 2013 data:

### Normal likelihood:

```{r}
priorsgwfullnormal <- c(set_prior("normal(500, 200)", class = "Intercept"),
             set_prior("normal(0,500)", class = "b",
                       coef = "cond"),
             set_prior("normal(0, 500)", class = "sd"),
             set_prior("normal(0, 1000)", class = "sigma"),
             set_prior("lkj(2)", class = "cor"))
```

```{r message = FALSE, results = "hide", cache=TRUE}
m_gwfullnormal<-brm(rt~cond + (1+cond|subj)+(1+cond|item),
               family=gaussian(), prior=priorsgwfullnormal,
              warmup=1000,
              iter=2000,
              cores=4,
              data = df_gibsonwu)
```


### Log-normal likelihood:

```{r}
priorsgwfulllogn <- c(set_prior("normal(6, 0.6)", class = "Intercept"),
             set_prior("normal(0,1)", class = "b",
                       coef = "cond"),
             set_prior("normal(0, 1)", class = "sd"),
             set_prior("normal(0, 1)", class = "sigma"),
             set_prior("lkj(2)", class = "cor"))
```

```{r message = FALSE, results = "hide", cache=TRUE}
m_gwfulllogn<-brm(rt~cond + (1+cond|subj)+(1+cond|item),
               family=lognormal(), prior=priorsgwfulllogn,
              warmup=1000,
              iter=2000,
              cores=4,
              data = df_gibsonwu,
              control=list(adapt_delta=0.99, max_treedepth=15))
```


(a) Posterior predictive distributions

Gibson and Wu (2013) data:

```{r}
pp_gwnormal<-pp_check(m_gwfullnormal,ndraws=1000)
pp_gwlogn<-pp_check(m_gwfulllogn,ndraws=1000)
cowplot::plot_grid(pp_gwnormal,pp_gwlogn,labels=c("Normal","Log-normal"),label_size=12,ncol=1)
```

In the Gibson and Wu (2013) data, the normal likelihood leads to a pretty dramatic mismatch between the observed and posterior predictive values; negative values are generated. The log-normal has a better match.

The replication attempt of Gibson and Wu (2013):

```{r message = FALSE, results = "hide", cache=TRUE}
m_gw2fullnormal<-brm(rt~cond + (1+cond|subj)+(1+cond|item),
               family=gaussian(), prior=priorsgwfullnormal,
              warmup=1000,
              iter=2000,
              cores=4,
              data = df_gibsonwu2)

m_gw2fulllogn<-brm(rt~cond + (1+cond|subj)+(1+cond|item),
               family=lognormal(), prior=priorsgwfulllogn,
              warmup=1000,
              iter=2000,
              cores=4,
              data = df_gibsonwu2)
```

```{r}
pp_gw2normal<-pp_check(m_gw2fullnormal,ndraws=1000)
pp_gw2logn<-pp_check(m_gw2fulllogn,ndraws=1000)
cowplot::plot_grid(pp_gwnormal,pp_gwlogn,labels=c("Normal","Log-normal"),label_size=12,ncol=1)
```

Here we have the same situation as in the first data set: assuming a normal likelihood yields a posterior predictive distribution that has negative values; the log-normal produces more realistic values.

(b) Gibson and Wu (2013) effect estimates:

```{r}
plot(m_gwfullnormal)

gw_intercept <- as_draws_df(m_gwfullnormal)$b_Intercept
gw_slope <- as_draws_df(m_gwfullnormal)$b_cond

gw_interceptln <- as_draws_df(m_gwfulllogn)$b_Intercept
gw_slopeln <- as_draws_df(m_gwfulllogn)$b_cond

gw_RT_diffnormal <- gw_slope
quantile(gw_RT_diffnormal,prob=c(0.025,0.975))
```

```{r}
gw_RT_difflogn <- exp(gw_interceptln + gw_slopeln/2) -
    exp(gw_interceptln - gw_slopeln/2)

quantile(gw_RT_difflogn,prob=c(0.025,0.975))
```

The effect estimate is much smaller, and has a smaller 95\% credible interval, with the log-normal likelihood. This is because there are a few extreme values in the data that bias the mean effect in subject relatives:

```{r}
boxplot(rt~type,df_gibsonwu)
```

The same thing happens with the replication attempt of the Gibson and Wu design:

```{r}
gw2_intercept <- as_draws_df(m_gw2fullnormal)$b_Intercept
gw2_slope <- as_draws_df(m_gw2fullnormal)$b_cond


gw2_interceptln <- as_draws_df(m_gw2fulllogn)$b_Intercept
gw2_slopeln <- as_draws_df(m_gw2fulllogn)$b_cond

gw2_RT_diffnormal <- gw2_slope
quantile(gw2_RT_diffnormal,prob=c(0.025,0.975))
```

```{r}
gw2_RT_difflogn <- exp(gw2_interceptln + gw2_slopeln/2) -
    exp(gw2_interceptln - gw2_slopeln/2)

quantile(gw2_RT_difflogn,prob=c(0.025,0.975))
```

```{r}
boxplot(rt~condition,df_gibsonwu2)
```

(c) The log-normal is better because it yields more realistic posterior predictive data and the estimate of the effect is not unduly affected by a few extreme values.

Using an informative prior (the posterior of a preceding study) for the next study:

```{r}
summary(m_gw2fulllogn)
```

Based on the posterior from the Gibson and Wu (2013) analysis, the posterior for the effect on the log scale is Normal(-0.08,0.065).

```{r}
priorsgwfulllogninf <- c(set_prior("normal(6, 0.6)", class = "Intercept"),
             set_prior("normal(-0.08,0.065)", class = "b",
                       coef = "cond"),
             set_prior("normal(0, 1)", class = "sd"),
             set_prior("normal(0, 1)", class = "sigma"),
             set_prior("lkj(2)", class = "cor"))
```

```{r message = FALSE, results = "hide", cache=TRUE}
m_gwfulllogninf<-brm(rt~cond + (1+cond|subj)+(1+cond|item),
               family=lognormal(), prior=priorsgwfulllogninf,
              warmup=1000,
              iter=2000,
              cores=4,
              data = df_gibsonwu2,
              control=list(adapt_delta=0.99, max_treedepth=15))
```

```{r}
summary(m_gwfulllogninf)
```

Next, we pool the data and fit the model again:

```{r}
colnames(df_gibsonwu)
colnames(df_gibsonwu2)[3]<-"type"
df_gibsonwu2<-df_gibsonwu2[,c(1,2,3,5,7)]

df_gibsonwu$subj<-paste("gw",df_gibsonwu$subj,sep="")
df_gibsonwu2$subj<-paste("gw2",df_gibsonwu2$subj,sep="")
pooled_gw<-rbind(df_gibsonwu,df_gibsonwu2)

priorsgwfulllognuninf <- c(set_prior("normal(6, 0.6)", class = "Intercept"),
             set_prior("normal(0,1)",
                       class = "b",
                       coef = "cond"),
             set_prior("normal(0, 1)", class = "sd"),
             set_prior("normal(0, 1)", class = "sigma"),
             set_prior("lkj(2)", class = "cor"))
```

```{r message = FALSE, results = "hide", cache=TRUE}
m_gwfulllognpooled<-brm(rt~cond + (1+cond|subj)+(1+cond|item),
               family=lognormal(), prior=priorsgwfulllognuninf,
              warmup=1000,
              iter=2000,
              cores=4,
              data = pooled_gw,
              control=list(adapt_delta=0.99, max_treedepth=15))
```

```{r}
summary(m_gwfulllognpooled)
```

We do get similar estimates by incrementally using the posterior from a previous study as a prior for a subsequent study, and from pooling the data.

## Exercise 4

```{r}
data("df_dillonE1")
dillonE1 <- df_dillonE1
```

First we set the contrast coding so that:

$$ \mu_{low} = \alpha +1 \cdot \beta  $$
$$ \mu_{high} = \alpha +- 1 \cdot \beta  $$


```{r}
dillonE1 <- dillonE1 %>%
mutate(int_meff = if_else(int == "low", 1, -1))
```

```{r, message = FALSE, results = "hide",cache=TRUE}
fit_dillonE1 <- brm(rt ~ int_meff + (int_meff | subj) + (int_meff | item),
  family = lognormal(),
  prior =
    c(
      prior(normal(6, 1.5), class = Intercept),
      prior(normal(0, 1), class = b),
      prior(normal(0, 1), class = sigma),
      prior(normal(0, 1), class = sd),
      prior(lkj(2), class = cor)
    ),
  data = dillonE1
)
```

```{r}
print(fit_dillonE1)
```

```{r}
posterior_summary(fit_dillonE1, variable = "b_int_meff")
```

There is some indication that the low interference conditions have slower rt, as predicted.

## Exercise 5


```{r}
data("df_ab")
```

```{r, message = FALSE, results = "hide", cache=TRUE}
fit_ab <- brm(probe_correct ~ lag + (lag | subj),
  family = bernoulli(),
  prior =
    c(
      prior(normal(6, 1.5), class = Intercept),
      prior(normal(0, 1), class = b),
      prior(normal(0, 1), class = sd),
      prior(lkj(2), class = cor)
    ),
  data = df_ab
)
```

```{r}
fit_ab
```



## (a) How is the accuracy of the probe identification affected by the lag? Estimate this in log-odds and percentages.

In log odds:
```{r}
posterior_summary(fit_ab, variable = "b_lag")
```

From lag 0 to lag 1 the accuracy increases by

```{r}
alpha_samples <- as_draws_df(fit_ab)$b_Intercept
beta_samples <- as_draws_df(fit_ab)$b_lag
effect_lag1_0 <- plogis(alpha_samples + 1* beta_samples) - plogis(alpha_samples) 

c(mean = mean(effect_lag1_0),
quantile(effect_lag1_0, c(0.025, 0.975)))

```


## (b) Is the linear relationship justified? Use posterior predictive checks to verify this.

```{r}
pp_check(fit_ab,
         type = "stat_grouped",
         stat = "mean",
         group = "lag",
         facet_args = list(
           ncol = 1, scales = "fixed"
           ),
         binwidth = 0.02
         )
```

Computing the mean log odds for each lag by hand:

```{r}
probs_by_lag<-with(df_ab,tapply(probe_correct,lag,mean))

logodds_by_lag<-qlogis(probs_by_lag)

plot(logodds_by_lag,type="l")
```

It seems that below lag 3 (lag 0, lag 1, lag 2), lag has a negative effect on the log odds of detection, and from lag>=3, it reverses the lag increases the log-odds of detection. We see this in the plot (also see below): The average proportion of detections goes from 1 to 0 (in lags 0, 1, 2) in log odds space, and then it starts to increase again. A model that assumes only a monotonically increasing effect of lag can't take that into account.

This was not asked for in the exercise, but one can think about a better relationship between lag and accuracy. Fit a new model and use posterior predictive checks to verify if the fit improved.

The new model introduces a new term with an interaction to account for the U shape relationship (but the model  is still linear). 

- if lag $\geq$ 3, the model in log odds is reduced to

$\alpha + \beta_1 \times \hbox{lag}$ 

- if lag $<$ 3, the model in log odds is 

$\alpha + \beta_1 \times  \hbox{lag} + \beta_2 \times 1 + \beta_3\times  \hbox{lag} = \alpha +  \beta_2 + (\beta_1+\beta_3)\times  \hbox{lag}$


```{r, message = FALSE, results = "hide", cache=TRUE}
fit_ab2 <- brm(probe_correct ~ lag * I(lag < 3) + (lag * I(lag < 3)  | subj),
  family = bernoulli(link= logit),
  prior =
    c(prior(normal(0, 1.5), class = Intercept),
      prior(normal(0, 0.5), class = b, coef = lag),
      prior(normal(0, 1), class = sd, coef = Intercept, group = subj),
      prior(normal(0, 1), class = sd, coef = lag, group = subj),
      prior(lkj(2), class = cor, group = subj)
    ),
  iter = 2000,
  warmup = 1000,
  control = list(adapt_delta = 0.99),
  data = df_ab
)
```

```{r}
fit_ab2
```

```{r}
pp_check(fit_ab2,
         type = "stat_grouped",
         stat = "mean",
         group = "lag",
         facet_args = list(
           ncol = 1, scales = "fixed"
           ),
         binwidth = 0.02
         )
```

This seems to account for the observed pattern a bit better. 

