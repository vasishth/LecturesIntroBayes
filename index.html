<!DOCTYPE html>
<html lang="en">
<head>

  <!-- Basic Page Needs
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <meta charset="utf-8">
  <title>Shravan Vasishth's Intro Bayes course home page</title>
  <meta name="description" content="">
  <meta name="author" content="Shravan Vasishth">

  <!-- Mobile Specific Metas
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- FONT
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link href="//fonts.googleapis.com/css?family=Raleway:400,300,600" rel="stylesheet" type="text/css">

  <!-- CSS
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="stylesheet" href="css/normalize.css">
  <link rel="stylesheet" href="css/skeleton.css">

  <!-- Favicon
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="icon" type="image/png" href="images/lorikeet.jpg">

</head>
<body>


<section>
  <div class="container">


<div class="column">

<p>
  <h3>Introduction to Bayesian data analysis for cognitive science
      (<a href="https://bruno.nicenboim.me/bayescogsci">textbook</a>)</h3>

<br>


<iframe width="560" height="315" src="https://www.youtube.com/embed/pWow8Qe1snQ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<br><br><br>

  <h4>Video lectures by</h4>

  <a href="https://vasishth.github.io/">Shravan Vasishth</a>
  <br><br>

 <h4>Online version and source code for book</h4>

 The free online version of the book is available <a href="https://bruno.nicenboim.me/bayescogsci/">here</a>.
 You can access the source code for the book from <a href="https://github.com/bnicenboim/bayescogsci">here</a>.
You can buy a <a href="https://www.routledge.com/Introduction-to-Bayesian-Data-Analysis-for-Cognitive-Science/Nicenboim-Schad-Vasishth/p/book/9780367359331">physical copy</a> of the book too.

<br><br>

<h4>Why you might want to follow this course of lectures</h4>

<a href="https://youtu.be/9j8j_aFzUTs?si=Tf2los502Jbse0cT">Here</a>
is a talk I gave in Indiana University in September 2022. This talk
explains why I believe that researchers in linguistics and psychology need to
spend a little bit of time studying the statistical tools they need for their research.<br>

 In recent years, Bayesian methods have come to be widely adopted in all areas
 of science. This is in large part due to the development of sophisticated
 software for probabilisic programming; a recent example is the astonishing
 computing capability afforded by the language Stan (<a
 href="https://mc-stan.org">mc-stan.org</a>). <br>

 However, the underlying theory needed to
 use this software sensibly is often inaccessible because end-users don't
 necessarily have the statistical and mathematical background to read the
 primary textbooks (such as Gelman et al's classic Bayesian data analysis, 3rd
 edition).<br>

 In this book and the accompanying course, we seek to cover this gap, by providing a relatively
 accessible and technically non-demanding introduction to the basic workflow for
 fitting different kinds of linear (mixed) models using Stan. To illustrate the
 capability of Bayesian modeling, we will use the R package RStan and a powerful
 front-end R package for Stan called brms.
<br><br>

<h4>MOOC on OpenHPI</h4>

You can do a self-paced version of this course (chapters 1-4),
with auto-graded exercises, <a href="https://open.hpi.de/courses/bayesian-statistics2023">here</a>.
Some 5000 people have signed up for this course.
<br><br>

<h4>Is this course taught in person?</h4>

We regularly teach parts of this course in person at:

<ol>
<li>The annual <a href="https://vasishth.github.io/smlp/">Statistical Methods for Linguistics and Psychology (SMLP)</a>, Potsdam, Germany. This is an annual week-long summer school, held usually just before the AMLaP conference. Chapters 1-5 and 13 are covered in Intro Bayes, and the rest of the chapters in the Advanced Bayes track.</li>
<li>The annual <a href="https://www.mils.ugent.be/">Methods in Linguistic Sciences (MILS) summer school</a>, Gent, Belgium (in July usually). In this course, I cover chapters 1-5, and 13.</li>
<li>The University of Potsdam, Germany. This is a two-semester course that covers the entire book (except the last chapter).</li>
<li>The Indian Institute of Technology, Kanpur. <a href="https://sites.google.com/site/himanshuyadavjnu/">Himanshu Yadav</a>,  also teaches this material, in India.</li>
</ol>

<h4>Prerequisites</h4>

You must have a functioning computer to do this course.<br>

We also assume familiarity with <a href="https://cran.r-project.org/">R</a>. Participants will benefit most if they have
previously fit linear models and linear mixed models (using lme4) in R, in any
scientific domain within linguistics and psychology. No knowledge of calculus or
linear algebra is assumed (but will be helpful to know), but basic school level
mathematics knowledge is assumed.<br>

Finally, to follow this course, it is important to be familiar with the basics of
<a href="https://rmarkdown.rstudio.com/">R Markdown</a>.

Please read <a href="HW/SubmissionInstructions.pdf">the instructions</a> regarding homework submission (if you are submitting homework as part of a summer school course).

<br><br>

<h4>Please install the following software before watching the videos</h4>

We will be using the software <a href="http://cran.r-project.org/">R</a>, and <a
href="https://www.rstudio.com/">RStudio</a> or <a href="">Visual Studio Code</a>, so make sure you install these on
your computer. You should also install the R package <a
href="https://github.com/stan-dev/rstan/wiki/RStan-Getting-Started">rstan</a>;
the R package <a href="https://github.com/paul-buerkner/brms">brms</a>, and all the packages mentioned in the introduction to the book.
<strong>Please follow the installation instructions carefully</strong>.<br>

Install the library bcogsci from <a href="https://github.com/bnicenboim/bcogsci">here</a>.
<br><br>

<h4>Outcomes</h4>

After completing this course, the participant will have become familiar with the
foundations of Bayesian inference using brms, and will be able to fit a range of
multiple regression models and hierarchical models, for normally distributed
data, and for lognormal and binomially distributed data. They will know how to
calibrate their models using prior and posterior predictive checks.

<br><br>

<ol>
  <li>Lecture on chapter 1 (Foundations):
  <ol>
    <li><a href="https://youtu.be/o6DwBhkSxWw">Video lecture on chapter 1</a>.
    </li>
    <li>Lecture notes:  <a href="lecturenotes/01.pdf">PDF</a>,
      <a href="lecturenotes/01.html">html</a>,
        <a href="lecturenotes/01.Rmd">Source code (Rmd).</a>
        </li>
      <li>Loading libraries: Place this in your current working directory and load the code in this file to load all needed packages <a href="index.R">index.R</a></li>
      <li>HW 0:  <a href="HW/HW0_Ch01.pdf">PDF</a>,
        <a href="HW/HW0_Ch01.Rmd">Source code (Rmd).</a>
        </li>
        <li><a href="https://youtu.be/zFR4F1OG7Js">Additional lecture: Frequentist foundations (Part 1/2)</a>,
            <a href="https://youtu.be/BtP1IbzBxIU">Additional lecture: Frequentist foundations (Part 2/2)</a>.
        Lecture notes: <a href="lecturenotes/01FF.pdf">PDF</a>, <a href="lecturenotes/01FF.html">html</a>, <a href="lecturenotes/01FF.Rmd">Source code (Rmd)</a> </li>
   </ol>
   <li>Lecture on chapter 2 (Analytical Bayes: the Beta-Binomial and the Poisson-Gamma conjugate cases):
  <ol>
     <li><a href="https://youtu.be/ZUPvN3AD8bM">Video lecture on chapter 2</a>.
    </li>
    <li>Lecture notes:  <a href="lecturenotes/02.pdf">PDF</a>,
      <a href="lecturenotes/02.html">html</a>,
        <a href="lecturenotes/02.Rmd">Source code (Rmd).</a>
        </li>
    <li>Data for lecture 2 (Poisson-Gamma example):  <a href="data/TRCexample.txt">here</a>
        </li>
    <li>Additional online video lecture on sampling algorithms: <a href="https://youtu.be/ymuLt6LBTwY?si=IZZtXh4umi3Vwu1C">here</a>.
    </li>
    <li>HW 1:  <a href="HW/HW1_Ch02.pdf">PDF</a>,
        <a href="HW/HW1_Ch02.Rmd">Source code (Rmd).</a>
    </li>
  </ol>
     <li>Lecture on chapter 3 (Computational Bayes: Regression models):
  <ol>
     <li><a href="https://youtu.be/zvdlA2UHeL0">Video lecture on chapter 3</a>.
    </li>
    <li>Lecture notes:  <a href="lecturenotes/03.pdf">PDF</a>,
      <a href="lecturenotes/03.html">html</a>,
        <a href="lecturenotes/03.Rmd">Source code (Rmd).</a>
        </li>
   <li>HW 2:  <a href="HW/HW2_Ch03.pdf">PDF</a>,
        <a href="HW/HW2_Ch03.Rmd">Source code (Rmd).</a>
    </li>
  </ol>
     <li>Lecture on chapter 4 (Computational Bayes: Multiple regression models):
  <ol>
     <li><a href="https://youtu.be/k4zSaNktoZY">Video lecture on chapter 4</a>.
    </li>
    <li>Lecture notes:  <a href="lecturenotes/04.pdf">PDF</a>,
      <a href="lecturenotes/04.html">html</a>,
        <a href="lecturenotes/04.Rmd">Source code (Rmd).</a>
        </li>
        <li>HW 3:  <a href="HW/HW3_Ch04.pdf">PDF</a>,
        <a href="HW/HW3_Ch04.Rmd">Source code (Rmd).</a>
    </li>
  </ol>
    <li>Lecture on chapter 5 (Hierarchical models):
  <ol>
     <li><a href="https://youtu.be/yD014eQKTpw">Video lecture on chapter 5</a>.
    </li>
    <li>Lecture notes:  <a href="lecturenotes/05.pdf">PDF</a>,
      <a href="lecturenotes/05.html">html</a>,
        <a href="lecturenotes/05.Rmd">Source code (Rmd).</a>
        </li>
      <li>HW 4:  <a href="HW/HW4_Ch02.pdf">PDF</a>,
        <a href="HW/HW4_Ch05.Rmd">Source code (Rmd).</a>
    </li>
  </ol>
    <li>Lecture on chapter 13 (Bayes factors):
  <ol>
     <li><a href="">Video lecture on chapter 13 (Coming soon)</a>.
    </li>
    <li>Lecture notes:  <a href="lecturenotes/13.pdf">PDF</a>,
      <a href="lecturenotes/13.html">html</a>,
        <a href="lecturenotes/13.Rmd">Source code (Rmd).</a>
        </li>
    <li>HW 5:  <a href="HW/HW5_Ch13.pdf">PDF</a>,
        <a href="HW/HW5_Ch13.Rmd">Source code (Rmd).</a>
    </li>
  </ol>
</ol>

<h4>Solutions to exercises</h4>

Solutions to exercises are not publicly available; they will only be provided to participants.<br><br>

<h4>Tutorial articles on specific topics</h4>


Here are some notes and articles that provide background reading, and cover some
additional topics that we will skip:

<ol>
<li>Why teaching statistics with a cookbook approach doesn't work (video lecture coming soon).</li>
 <li>Mathematical foundations: <a href="https://www.youtube.com/playlist?list=PL0TWbOjq4HH1Y1-PBA_guwZ482G8kQHHW">Video lectures</a>,
  <a href="https://openup.uni-potsdam.de/enrol/index.php?id=350">enroll here for online self-paced course</a>.</li>
 <li>Linear modeling: <a href="https://github.com/vasishth/LM">Lecture notes</a>.</li>
 <li>Deciding on sample sizes from a Bayesian perspective: <a href="https://link.springer.com/article/10.1007/s42113-021-00125-y">Sample size determination for Bayesian hierarchical models commonly used in psycholinguistics</a>.
Shravan Vasishth, Himanshu Yadav, Daniel Schad, and Bruno Nicenboim.
Computational Brain and Behavior, 2022.</li>
 <li> brms tutorial:
 <a href="https://econpapers.repec.org/article/jssjstsof/v_3a080_3ai01.htm">brms tutorial by the author of the package, Paul Buerkner.</a>
<li><a href="https://psyarxiv.com/x8swp/">Ordinal regression models in psychological research: A tutorial, by Buerkner and Vuorre.</a></li>
  <li> Bayesian workflow tutorial:
 <a href="https://osf.io/b2vx9/">Bayesian workflow tutorial, by Schad, Betancourt, Vasishth</a>.
</li>
  <li>Intro to Bayes for phonetics:
 <a href="https://osf.io/g4zpv/">brms tutorial for phonetics/phonology, Vasishth, Nicenboim, Beckman, Li, Kong.</a>
</li>
<li>Developing a reproducible workflow: <a href="https://vasishth.github.io/ReproducibleWorkflows/">Lecture notes</a></li>
<li><a href="https://betanalpha.github.io/writing/">Michael Betancourt's resources</a>: These are a must if you want to get deeper into Stan and Bayesian modeling.</li>
<li><a href="https://chi-feng.github.io/mcmc-demo/app.html">MCMC animations/visualizations</a>,<a href="http://elevanth.org/blog/2017/11/28/build-a-better-markov-chain/">McElreath's blog post on MCMC</a></li>

</ol>

<h4>Some example articles that use Bayesian methods from our lab</h4>

A frequently asked question is: how to summarize the results of a Bayesian
analysis? Here are some examples of articles we have published using Bayesian
data analysis. Our presentation of results is continuously evolving; there is no
fixed answer to the question, how should I display my results? Use your
judgement. The most important thing you can do to facilitate understanding of
your work is to be open and transparent about your analyses. This means
releasing all data and code with the published paper (see the <a href="https://vasishth.github.io/ReproducibleWorkflows/">reproducible workflows lecture above</a>).

For other papers that use Bayesian methods, see my post-2012 <a href="https://vasishth.github.io/publications.html">publications</a>.

<ol>
<li>
 <a href="https://doi.org/10.1016/j.jml.2017.01.004">Example random-effects meta-analysis.</a>
</li>
  <li>
 <a href="https://doi.org/10.1016/j.jml.2017.08.004">Example of finite mixture models using Stan.</a>
 <li><a href="https://doi.org/10.1111/cogs.13186">Example of a multinomial processing tree modeling approach</a>.</li>
</li>
<li><a href="https://doi.org/10.1016/j.jml.2024.104514">Replication attempt of a published study.</a></li>
<li><a href="https://doi.org/10.1016/j.jml.2022.104400">Example from psycholinguistics of model comparison using k-fold cross-validation.</a></li>
</ol>
</p>
</div>
</div>

</section>
</body>
</html>
